<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dave J Kane</title>
    <link>https://davejkane.github.io/index.xml</link>
    <description>Recent content on Dave J Kane</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Fri, 25 Nov 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://davejkane.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Embedding a D3 graph in a Hugo website</title>
      <link>https://davejkane.github.io/post/d3-hugo/</link>
      <pubDate>Fri, 25 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/post/d3-hugo/</guid>
      <description>

&lt;h2 id=&#34;hugo-and-d3&#34;&gt;Hugo and D3&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve seen a couple of posts on forums asking how to get a D3 graph or animation using a static site generator like Hugo. It&amp;rsquo;s actually very simple. You see, you can put HTML right in along side your markdown.&lt;/p&gt;

&lt;h2 id=&#34;adding-a-container-div&#34;&gt;Adding a Container div&lt;/h2&gt;

&lt;p&gt;So what you want to do is, in your markdown file, create a Div with an ID where you want to put the graph. Like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Some smart heading
blah blah blah, interesting fact nugget about data
and here&#39;s a graph that shows off my wisdom
&amp;lt;div id=&amp;quot;myGraph&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;attaching-to-your-div-in-your-javascript&#34;&gt;Attaching to your div in your javascript&lt;/h2&gt;

&lt;p&gt;So then, in your javascript you want to do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var svg = d3.select(&amp;quot;#myGraph&amp;quot;)
.append(&amp;quot;svg&amp;quot;)
....
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;saving-your-javascript-in-a-separate-file&#34;&gt;Saving your javascript in a separate file&lt;/h2&gt;

&lt;p&gt;One caveat. You&amp;rsquo;ll have to save your javascript as a separate file, because otherwise the markdown processor will escape out all the important javascript stuff and your graph won&amp;rsquo;t work. Most tutorials for D3 you see online have CSS and Javascript inline with the HTML, nuh uh. Don&amp;rsquo;t do that.&lt;/p&gt;

&lt;h2 id=&#34;loading-d3-first&#34;&gt;Loading D3 first.&lt;/h2&gt;

&lt;p&gt;So at the end of your markdown file, you&amp;rsquo;ll want to link to two scripts like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;https://d3js.org/d3.v4.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;/mygraph.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll need to load the D3 library first for your graph to render. No webpack here. Make sure to save your javascript file in your static folder. If you have a lot of static files, you may want to keep it in a separate js folder and then your script link will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;/js/mygraph.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So there you go, it&amp;rsquo;s very easy, the main things to consider are, keeping your js and css separate from your html, and creating the container div and script links as html directly in your markdown. I hope this helps.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Does Football Follow the Pareto Principal</title>
      <link>https://davejkane.github.io/post/does-football-follow-pareto/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/post/does-football-follow-pareto/</guid>
      <description>

&lt;p&gt;Let&amp;rsquo;s keep this first post nice and basic.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you&amp;rsquo;re intested in data science, you may be interested in the accompanying posts &lt;a href=&#34;https://davejkane.github.io/webscraping-fun-stats&#34;&gt;Web scraping for fun and stats&lt;/a&gt;, &lt;a href=&#34;https://davejkane.github.io/json-sqlite-csv&#34;&gt;JSON to SQLite to csv - Data transforations&lt;/a&gt; and &lt;a href=&#34;https://davejkane.github.io/D3-CDF-with-hover&#34;&gt;D3: A CDF graph with hover tooltips&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-pareto-principal&#34;&gt;The Pareto principal&lt;/h2&gt;

&lt;p&gt;Vilfredo Pareto was an Italian polymath who introduced some important concepts in microeconomics. But he&amp;rsquo;s mostly famous for his most meme-able observation: the &lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule. He noticed that in his time, about 20% of Italians owned about 80% of the land. Since then people have noticed this &lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule all over the place. 20% of your customers make up 80% of your sales. 20% of the global population have 80% of the wealth, 20% of your friends are having 80% of the sex. etc. etc.&lt;/p&gt;

&lt;h2 id=&#34;football&#34;&gt;Football&lt;/h2&gt;

&lt;p&gt;But our question is, does football fit this pattern? Specifically, I hypothesise that 20% of the players score 80% of the goals. And by players I mean anyone who at least made it to the bench, so no reserves. For our sample I&amp;rsquo;ll be using the last complete season of the English Premier League - 2015-16.&lt;/p&gt;

&lt;p&gt;So well, here&amp;rsquo;s our graph.&lt;/p&gt;

&lt;div id=&#34;paretoGraph&#34;&gt;&lt;/div&gt;

&lt;p&gt;You can hover over the individual data points of the bottom line to see the players and how many goals they scored. It&amp;rsquo;s a little cramped with so many data points.&lt;/p&gt;

&lt;p&gt;The bottom line represents the percentage of goals each player has scored whereas the top line represents the cumulation of the goals. The bottom line can easily mislead you into thinking that scoring is reasonably equally distributed, but the cumulation line you can clearly see that infact:&lt;/p&gt;

&lt;h2 id=&#34;it-s-true&#34;&gt;It&amp;rsquo;s True!&lt;/h2&gt;

&lt;p&gt;Around 20% of the players do indeed score around 80% of the goals.&lt;/p&gt;

&lt;h2 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;

&lt;p&gt;So that was a really basic alternative way to view some common football stats. I plan to follow up with more football related articles soon, especially seeing as I have a very detailed football data set. More about that &lt;a href=&#34;https://davejkane.github.io/webscraping-fun-stats&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;script src=&#34;https://d3js.org/d3.v4.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://davejkane.github.io/paretoscorers.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>A CDF Graph with Hover Tooltips Using D3.js</title>
      <link>https://davejkane.github.io/post/D3-CDF-with-hover/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/post/D3-CDF-with-hover/</guid>
      <description>

&lt;h1 id=&#34;creating-a-cdf-graph-with-d3-from-csv-data&#34;&gt;Creating a CDF graph with D3 from csv data&lt;/h1&gt;

&lt;p&gt;In this short post, I&amp;rsquo;ll show you how I made the cumulative density function graph, with hover over tooltips, as used in my previous post &lt;a href=&#34;https://davejkane.github.io/does-football-follow-pareto&#34;&gt;&amp;ldquo;Does football follow the pareto principal&amp;rdquo;&lt;/a&gt;. Nothing here is particularly innovative, it&amp;rsquo;s mostly reuse of code from the net.&lt;/p&gt;

&lt;h2 id=&#34;cdf-graph&#34;&gt;CDF graph.&lt;/h2&gt;

&lt;p&gt;First up, here&amp;rsquo;s the graph.&lt;/p&gt;

&lt;div id=&#34;paretoGraph&#34;&gt;&lt;/div&gt;

&lt;p&gt;And here&amp;rsquo;s the full code for the graph&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*Here up open up our csv file with the d3.csv function and load it into the dataset variable.
Our csv file contains two columms , players and goals with the names of the players and the
number of goals that player scored in the season. */
var dataSet;
d3.csv(&#39;../scorers.csv&#39;, function(d) {
    dataSet = d;

/*To make the cumulative line, create an array called cumgoals.
Loop through the dataset and append the cumulative goals to the array*/
cumGoals = [];
cumGoals.push(dataSet[0].goals);
dataLength = dataSet.length;
for (i = 1; i &amp;lt; dataLength; i++) {
    cumGoals.push(parseInt(dataSet[i].goals) + parseInt(cumGoals[i - 1]))
};

/*Calculate the total number of goals.*/
totalGoals = d3.sum(dataSet, function(d) {
    return d.goals;
});

/*Defining the margins, width and height of the graph.*/
var margin = {top: 30, right: 20, bottom: 50, left: 50},
width = 480 - margin.left - margin.right,
//Keep the height small for data banking
height = 240 - margin.top - margin.bottom;

/*Defining the x and y scales*/
var x = d3.scaleLinear().range([0, width]);
var y = d3.scaleLinear().range([height, 0]);

/*Define the axes*/
var formatAsPercentage = d3.format(&#39;.0%&#39;);
var xAxis = d3.axisBottom().scale(x).ticks(5).tickFormat(formatAsPercentage);
var yAxis = d3.axisLeft().scale(y).ticks(5).tickFormat(formatAsPercentage);

/*Create line function for percentage of goals per player*/
var valueline = d3.line()
.x(function(d, i) { return x(i / (dataSet.length - 1)); })
.y(function(d) { return y(d.goals / totalGoals)});

/*Create the line function for the cumulative line (CDF)*/
var totalline = d3.line()
.x(function(d, i){ return x(i / (dataSet.length - 1)); })
.y(function(d){
    return y(d / totalGoals);
});

// Define the div for the tooltip
var div = d3.select(&amp;quot;body&amp;quot;).append(&amp;quot;div&amp;quot;)   
.attr(&amp;quot;class&amp;quot;, &amp;quot;tooltip&amp;quot;)               
.style(&amp;quot;opacity&amp;quot;, 0);

// Create the SVG element
var svg = d3.select(&amp;quot;#paretoGraph&amp;quot;)
.append(&amp;quot;svg&amp;quot;)
    .attr(&amp;quot;width&amp;quot;, width + margin.left + margin.right)
    .attr(&amp;quot;height&amp;quot;, height + margin.top + margin.bottom)
.append(&amp;quot;g&amp;quot;)
    .attr(&amp;quot;transform&amp;quot;, 
          &amp;quot;translate(&amp;quot; + margin.left + &amp;quot;,&amp;quot; + margin.top + &amp;quot;)&amp;quot;);

// Scale the range of the data
x.domain([0, 1]);
y.domain([0, 1]);


// Add the valueline path.
svg.append(&amp;quot;path&amp;quot;)
    .attr(&amp;quot;class&amp;quot;, &amp;quot;line&amp;quot;)
    .attr(&amp;quot;d&amp;quot;, valueline(dataSet));

// Add the totalline path
svg.append(&amp;quot;path&amp;quot;)
    .attr(&amp;quot;class&amp;quot;, &amp;quot;line&amp;quot;)
    .attr(&amp;quot;d&amp;quot;, totalline(cumGoals));


// Add the scatterplot
svg.selectAll(&amp;quot;dot&amp;quot;)    
    .data(dataSet)          
.enter().append(&amp;quot;circle&amp;quot;)                               
    .attr(&amp;quot;r&amp;quot;, 2)       
    .attr(&amp;quot;cx&amp;quot;, function(d, i) { return x(i / (dataSet.length - 1)); })      
    .attr(&amp;quot;cy&amp;quot;, function(d) { return y(d.goals / totalGoals); })
    .on(&amp;quot;mouseover&amp;quot;, function(d) {      
        div.transition()        
            .duration(200)      
            .style(&amp;quot;opacity&amp;quot;, .9);      
        div .html(d.players + &#39;: &#39; + d.goals)   
            .style(&amp;quot;left&amp;quot;, (d3.event.pageX) + &amp;quot;px&amp;quot;)     
            .style(&amp;quot;top&amp;quot;, (d3.event.pageY - 28) + &amp;quot;px&amp;quot;);    
        })                  
    .on(&amp;quot;mouseout&amp;quot;, function(d) {       
        div.transition()        
            .duration(500)      
            .style(&amp;quot;opacity&amp;quot;, 0);   
    });

// Add the X Axis
svg.append(&amp;quot;g&amp;quot;)
    .attr(&amp;quot;class&amp;quot;, &amp;quot;x axis&amp;quot;)
    .attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(0,&amp;quot; + height + &amp;quot;)&amp;quot;)
    .call(xAxis);

// Add the X Axis label
svg.append(&amp;quot;text&amp;quot;)
        .attr(&amp;quot;transform&amp;quot;, &amp;quot;translate(&amp;quot; + (width / 2) + &amp;quot; ,&amp;quot; + (height + margin.bottom - 10) + &amp;quot;)&amp;quot;)
        .style(&amp;quot;text-anchor&amp;quot;, &amp;quot;middle&amp;quot;)
        .text(&amp;quot;Percent of Players&amp;quot;);

// Add the Y Axis
svg.append(&amp;quot;g&amp;quot;)
    .attr(&amp;quot;class&amp;quot;, &amp;quot;y axis&amp;quot;)
    .call(yAxis);

// Add the Y Axis label
svg.append(&amp;quot;text&amp;quot;)
        .attr(&amp;quot;transform&amp;quot;, &amp;quot;rotate(-90)&amp;quot;)
        .attr(&amp;quot;y&amp;quot;, 0 - margin.left)
        .attr(&amp;quot;x&amp;quot;,0 - (height / 2))
        .attr(&amp;quot;dy&amp;quot;, &amp;quot;1em&amp;quot;)
        .style(&amp;quot;text-anchor&amp;quot;, &amp;quot;middle&amp;quot;)
        .text(&amp;quot;Percent of Goals&amp;quot;);

// Close the csv function
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So hopefully that reads well enough. As I said, there&amp;rsquo;s nothing particularly innovative about this graph.&lt;/p&gt;

&lt;script src=&#34;https://d3js.org/d3.v4.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://davejkane.github.io/paretoscorers.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>JSON to SQLite to csv with Python</title>
      <link>https://davejkane.github.io/post/json-sqlite-csv/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/post/json-sqlite-csv/</guid>
      <description>

&lt;h1 id=&#34;json-to-sqlite-to-csv-with-python&#34;&gt;JSON to SQLite to csv with python.&lt;/h1&gt;

&lt;p&gt;So if you read my last post about webscraping and saving a whole bunch of JSON files, then there&amp;rsquo;s a small chance that you might have just that - a whole bunch of similar JSON files. In this post I&amp;rsquo;ll run you through my process to take JSON data, saved across multiple files and transform that data into SQLite tables. In my case it&amp;rsquo;s a whole bunch of football stats saved in JSON format that I want to enter into a highly normalised SQL database. I&amp;rsquo;ll then run through how to get the SQLite data into csv format. We&amp;rsquo;ll use the command line SQLite tool for this.&lt;/p&gt;

&lt;h2 id=&#34;json-to-objects&#34;&gt;JSON to objects&lt;/h2&gt;

&lt;p&gt;Absolutely the first thing you want to do is to try to describe the domain, to make a domain model. And then to think about how these models fit together. Think of it as Domain Driven Design (DDD) light. This isn&amp;rsquo;t so much about decoupling business logic from service layers as would the case in proper DDD. At the end of the day this is scripting, we&amp;rsquo;re not building software here.&lt;/p&gt;

&lt;p&gt;The focus will be on describing the domain and using composition to handle the creation of objects. I want to make a highly normalised database. For the kind of thing where you are going to be writing very few queries, but where the queries are complex, it makes sense to normalise our data. That means that goals will be stored separately from matches and to get the goals from any given match, will require a table join. It also means to get all the goals for any given player, we won&amp;rsquo;t need to join through a Match table or anything like that. So for example, where many football databases save information about Red Cards, or Yellow Cards right in the match table, I like to have those in their own tables with a Foreign Key to the match table and to the player table and to the team table.&lt;/p&gt;

&lt;p&gt;For each python class I recommend a minimum of three methods&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class myClass:
    def __init__():
        #Initialise the object, obvious choice.
    def __str__():
        #Handle printing behaviour. Really useful to make sure the objects have been created properly. 
    def Insert():
        #Handle inserting the object data into the SQLite database.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Insert() method is really going to clean up the code in your script, especially when you have a list of objects&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for myObject in myObjects:
    myObject.Insert()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simple. So basically, I recommend breaking the objects down into as many separate things as is practical. We don&amp;rsquo;t want to store xml strings or anything in our databases because we&amp;rsquo;re trying to cram too much information into our tables. In my database I settled for the following tables, and thus objects.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Season - Contains the name of the competition and the year.&lt;/li&gt;
&lt;li&gt;Referee&lt;/li&gt;
&lt;li&gt;Team&lt;/li&gt;
&lt;li&gt;Player&lt;/li&gt;
&lt;li&gt;Stadium - Probably should have gone in the team table, seeing as I&amp;rsquo;m only dealing with league data.&lt;/li&gt;
&lt;li&gt;Game&lt;/li&gt;
&lt;li&gt;Appearance - A relationship table for players and games, due to the many to many relationship.&lt;/li&gt;
&lt;li&gt;Goal&lt;/li&gt;
&lt;li&gt;Assist - Could be stored in the goal table.&lt;/li&gt;
&lt;li&gt;Yellow Card&lt;/li&gt;
&lt;li&gt;Red Card - Yellow and red card could be stored in the same table.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A final note - where you need an Autoincrementing primary key for your table, you don&amp;rsquo;t want to store that in your python object, nor do you want to store Foreign Key references in the object. Instead pass those as parameters to the Insert method.&lt;/p&gt;

&lt;h2 id=&#34;creating-the-sqlite-database-and-tables&#34;&gt;Creating the sqlite database and tables.&lt;/h2&gt;

&lt;p&gt;At the top of your script you want to connect to your SQLite database, if the database doesn&amp;rsquo;t exist, SQLite will make it for you. Man I love that feature. Then you want to create the tables, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import sqlite3 as lite

con = lite.connect(&#39;test.db&#39;)
cur = con.cursor()

cur.execute(&amp;quot;CREATE TABLE IF NOT EXISTS Season (id INTEGER PRIMARY KEY AUTOINCREMENT, Competition TEXT, Year INTEGER)&amp;quot;)

cur.execute(&amp;quot;CREATE TABLE IF NOT EXISTS Referee (Name TEXT PRIMARY KEY)&amp;quot;)

cur.execute(&amp;quot;CREATE TABLE IF NOT EXISTS Team (Name Text PRIMARY KEY)&amp;quot;)

cur.execute(&amp;quot;CREATE TABLE IF NOT EXISTS Player (Name TEXT PRIMARY KEY, DOB INTEGER, Nation TEXT, Goalkeeper INTEGER)&amp;quot;)

cur.execute(&amp;quot;CREATE TABLE IF NOT EXISTS Stadium (Name TEXT PRIMARY KEY, TeamName TEXT, FOREIGN KEY(TeamName) REFERENCES Team(Name))&amp;quot;)
# and so on and so on...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that I don&amp;rsquo;t use any kind of ORM. Personally, I like SQL, and I prefer to write it directly. I think it&amp;rsquo;s good skill to have in data science, you won&amp;rsquo;t always be able to use an ORM, but you can always query with SQL.&lt;/p&gt;

&lt;p&gt;Then create your classes. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Competition:
    def __init__(self, league, year):
        self.league = league
        self.year = year

    def __str__(self):
        return &amp;quot;League: {}, Year:{}&amp;quot;.format(self.league, self.year)

    def insert(self, con, cur):
        cur.execute(&amp;quot;INSERT OR IGNORE INTO Season (Competition, Year) VALUES (?, ?)&amp;quot;, (self.league, self.year))
        con.commit()


class Referee:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return &amp;quot;Referee: {}&amp;quot;.format(self.name)

    def insert(self, con, cur):
        cur.execute(&amp;quot;INSERT OR IGNORE INTO Referee (Name) VALUES (?)&amp;quot;, (self.name,))
        con.commit()


class Team:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return &amp;quot;Team: {}&amp;quot;.format(self.name)

    def insert(self, con, cur):
        cur.execute(&amp;quot;INSERT OR IGNORE INTO Team (Name) VALUES (?)&amp;quot;, (self.name,))
        con.commit()


class Player:
    def __init__(self, name, DOB, nationality, goalkeeper):
        self.name = name
        self.DOB = DOB
        self.nationality = nationality
        #Goalkeeper is a boolean value
        self.goalkeeper = goalkeeper

    def __str__(self):
        return &amp;quot;PLAYER - Name: {}, DOB: {}, Nationality: {}, Is Goalkeeper: {}&amp;quot;.format(self.name, self.DOB, self.nationality, self.goalkeeper)

    def insert(self, con, cur):
        cur.execute(&amp;quot;INSERT OR IGNORE INTO Player (Name, DOB, Nation, Goalkeeper) VALUES (?, ?, ?, ?)&amp;quot;, (self.name, self.DOB, self.nationality, self.goalkeeper))
        con.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The init and str methods are pretty standard fare. You&amp;rsquo;ll notice that on the insert methods, we pass the cursor and the connection to the method. It&amp;rsquo;s just a good way of being concise. It also make sure we don&amp;rsquo;t initialise a database connection every time we insert data. We do however commit after every insertion. I like to use judicious printing and regular committing, so I can pick up where I left off if something goes wrong.&lt;/p&gt;

&lt;p&gt;Other things to note, I use player names, team names and other such names as primary keys. You see, under the hood SQLite3 doesn&amp;rsquo;t actually make primary keys, it just makes unique indices. I know there were no two players called exactly the same thing so that also simplifies things. It also means we don&amp;rsquo;t have to insert and then retrieve the id when doing insertions. And we can do a simple &amp;ldquo;INSERT OR IGNORE&amp;rdquo; to prevent duplicates.&lt;/p&gt;

&lt;h2 id=&#34;looping-through&#34;&gt;Looping through&lt;/h2&gt;

&lt;p&gt;So now that you&amp;rsquo;ve created your tables, made your classes and given each class an insert method, you just need to loop through the JSON files and make all the insertions. So it starts like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for index in range(380): #For 380 games in a premier league season.
    file = &#39;game{}.json&#39;.format(index)
    with open(file, &#39;r&#39;) as data_file:
        data = json.load(data_file)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the insertion might look something like this. Remember, JSON objects are mapped to dicts so it works just like accessing nested elements in a dict.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;players = []
for teamList in data[&amp;quot;teamLists&amp;quot;]:
    for player in teamList[&amp;quot;lineup&amp;quot;]:
        if player[&amp;quot;matchPosition&amp;quot;] == &amp;quot;G&amp;quot;:
            players.append(Player(player[&amp;quot;name&amp;quot;][&amp;quot;display&amp;quot;], player[&amp;quot;birth&amp;quot;][&amp;quot;date&amp;quot;][&amp;quot;millis&amp;quot;], player[&amp;quot;birth&amp;quot;][&amp;quot;country&amp;quot;][&amp;quot;country&amp;quot;], 1))
        else:
            players.append(Player(player[&amp;quot;name&amp;quot;][&amp;quot;display&amp;quot;], player[&amp;quot;birth&amp;quot;][&amp;quot;date&amp;quot;][&amp;quot;millis&amp;quot;], player[&amp;quot;birth&amp;quot;][&amp;quot;country&amp;quot;][&amp;quot;country&amp;quot;], 0))

for player in players:
    player.insert(con, cur)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Apologies if the code wrapping makes that tricky to read. So we make a whole bunch of player objects and put them in a list called players, then we loop through the players list and insert the data into the database. Simples.&lt;/p&gt;

&lt;h2 id=&#34;there-you-go&#34;&gt;There you go&lt;/h2&gt;

&lt;p&gt;So this wasn&amp;rsquo;t exactly a walkthrough, but I hope you understand a possible process to scrape JSON data from a website, map it to a domain using basic Domain Driven Design, and creating a normalised SQLite database from the data. The only thing left to do is to query the data and save the results as a csv file that you can then use in a D3.js animation.&lt;/p&gt;

&lt;h2 id=&#34;querying-the-sqlite-database&#34;&gt;Querying the sqlite database&lt;/h2&gt;

&lt;p&gt;So I recommend creating an SQL file. Call it something clever like my_query.sql. Then in the terminal, you want to test your query on stdout first. so you would type&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sqlite3 mydatabase.db
&amp;gt;&amp;gt;&amp;gt; .mode column
&amp;gt;&amp;gt;&amp;gt; .headers ON
&amp;gt;&amp;gt;&amp;gt; .read my_query.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you don&amp;rsquo;t like the results, tweak your query and run it again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; .read my_query.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now your happy with it. For example this to get a list of all players and how many goals they scored.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT player.name AS players, 
       COUNT(goal.id) AS goals 
  FROM player 
       LEFT JOIN goal 
       ON player.name = goal.player
 GROUP BY players
 ORDER BY goals DESC;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then in the sqlite command you would do this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; .mode csv
&amp;gt;&amp;gt;&amp;gt; .output my_results.csv
&amp;gt;&amp;gt;&amp;gt; .read my_query.sql
&amp;gt;&amp;gt;&amp;gt; .exit
open my_results.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And there you have it, the easiest way to get csv data from SQlite. No python imports, no worrying about UTF-8, no csv writers etc. Just simple. Now, &lt;a href=&#34;https://davejkane.github.io/D3-CDF-with-hover&#34;&gt;creating a graph from the csv data.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Webscraping for Fun and Stats</title>
      <link>https://davejkane.github.io/post/webscraping-fun-stats/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/post/webscraping-fun-stats/</guid>
      <description>

&lt;h2 id=&#34;webscraping&#34;&gt;Webscraping&lt;/h2&gt;

&lt;p&gt;Webscraping is the art of programmatically browsing the web to retrieve information. It&amp;rsquo;s fun. You get to feel a bit like a hacker, even though you probably don&amp;rsquo;t actually want to hack into non-public facing websites to get data. And for a lot of publically available data, it is the most practical way to get it.&lt;/p&gt;

&lt;p&gt;Webscraping is not web crawling. Web crawling is more open ended and basically just used to index websites, rather than extract information. Webscraping can well be looked down upon as an evil act, with connotations of DDoS and cracking. But it&amp;rsquo;s also possible to scrape data from a website politely, without burdoning the webserver and breaching terms of use.&lt;/p&gt;

&lt;p&gt;The hardest bit about web scraping is findning good information and tools. And that&amp;rsquo;s where I hope this article can help. Many web scraping tools focus on interacting with the html returned from a HTTP request, but with the rise of modern javascript rendered websites, that approach is pretty limited, because increasingly the information you see on the page was sent with secondary requests, usually in the form of JSON or xml.&lt;/p&gt;

&lt;h2 id=&#34;the-solution-headless-web-browsing&#34;&gt;The solution - Headless Web Browsing.&lt;/h2&gt;

&lt;p&gt;The solution to this is to use a headless web browser and browse the site programmatically. A headless web browser is just a browser without a graphical interface, so you pretty much have to use programming to control it. But it&amp;rsquo;s easy. If you&amp;rsquo;re reading this you&amp;rsquo;ve already done the hard part of finding decent info. If I do say so myself.&lt;/p&gt;

&lt;h2 id=&#34;the-tools&#34;&gt;The tools&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re going to use python for this. It&amp;rsquo;s the goto language for such scripty things, but if your favourite programming language supports Selenium Web Driver, and it probably does, then feel free to use that instead. I hope the information in the rest of this post will still be useful to you.&lt;/p&gt;

&lt;h3 id=&#34;selenium-web-driver&#34;&gt;Selenium Web Driver&lt;/h3&gt;

&lt;p&gt;First install Selenium web driver. Selenium web driver provides an interface for you to control a browser programmatically. Just open up your favourite search engine, probably Bing, and search for &amp;ldquo;install selenium webdriver [your favourite programming language] [your operating system]&amp;rdquo;. Follow those instructions. This post isn&amp;rsquo;t the place to list all of the combinations of architectures and programming languages.&lt;/p&gt;

&lt;h3 id=&#34;phantomjs&#34;&gt;PhantomJS&lt;/h3&gt;

&lt;p&gt;Next you&amp;rsquo;re going to have to install PhantomJS. PhantomJS is the actual headless web browser that you will be controlling with Selenium. You&amp;rsquo;ll need NodeJS and the NPM to install it, so if you don&amp;rsquo;t have Node installed, head over to &lt;a href=&#34;https://nodejs.org&#34;&gt;nodejs.org&lt;/a&gt; and follow the installaton instructions for your computer.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve done that you can install PhantomJS from npm by typing the following into a terminal.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install phantomjs -g 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;acessing-a-page&#34;&gt;Acessing a page&lt;/h2&gt;

&lt;p&gt;Create a new python script &lt;strong&gt;whatever_you_want_to_call_it.py&lt;/strong&gt; and open it up in your favourite text editor and enter the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from selenium import webdriver
import time

driver = webdriver.PhantomJS()
driver.set_window_size(1024, 768)
driver.get(&#39;https://google.com&#39;)
print &#39;Sleeping&#39;
time.sleep(3)
driver.save_screenshot(&#39;screen.png&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Go ahead and run your script with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python whatever_you_called_your_file.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;open screen.png
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Wow, huh. pretty, pretty, pretty, pretty good. Consider that the &amp;ldquo;hello world&amp;rdquo; of webscraping. If you got it to work then you&amp;rsquo;re ready to scrape the web for fun and stats. That little sleep in there, that&amp;rsquo;s just to make sure all the javascript has rendered on the page. Not really a big deal when you&amp;rsquo;re only hitting up google.&lt;/p&gt;

&lt;h2 id=&#34;inspecting-with-developer-tools&#34;&gt;Inspecting with developer tools.&lt;/h2&gt;

&lt;p&gt;Right, I&amp;rsquo;m hoping you came here to find out how to get sports stats or some other publically available statistics, after reading my post &lt;a href=&#34;https://davejkane.github.io/does-football-follow-pareto&#34;&gt;Does football follow the pareto principal?&lt;/a&gt; So the first thing your going to want to do is head over to &lt;a href=&#34;http://www.bbc.com/sport/football/results&#34;&gt;BBC football results&lt;/a&gt; with chrome. I hope you&amp;rsquo;re using chrome, if not, try to follow along anyway, but make sure you&amp;rsquo;re using a browser with some sort of decent developer tools. For the record, I did not get my stats from the BBC, but I can&amp;rsquo;t tell you where I got them. Even though sports statistics are public knowledge, scraping a website to steal, I mean scrape them, probably goes against some kind of terms of service and is most likely frowned upon.&lt;/p&gt;

&lt;p&gt;Anyhoo, find a game that has a report link on the right side. Right click on the link and Inspect Element. I think that&amp;rsquo;s what it&amp;rsquo;s called, my chrome is in Danish. That will take you to the location of an anchor element for that link. Now in the element inspector, right click on the anchor element and select copy &amp;gt; copy selector.&lt;/p&gt;

&lt;p&gt;Cool now we&amp;rsquo;re ready to get the link for that programmatically.&lt;/p&gt;

&lt;h2 id=&#34;retrieving-information-with-selenium&#34;&gt;Retrieving information with selenium&lt;/h2&gt;

&lt;p&gt;So let&amp;rsquo;s change our script to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from selenium import webdriver
import time

driver = webdriver.PhantomJS()
driver.set_window_size(1024, 768)
driver.get(&#39;https://google.com&#39;)
print &#39;Sleeping&#39;
time.sleep(3)
link = driver.find_element_by_css_selector(&#39;PASTE_YOUR_SELECTOR_HERE&#39;)
print link.get_attribute(&#39;href&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively you could have copied the XPath from developer tools and used&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;driver.find_element_by_xpath()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;instead. I prefer css selectors just because I&amp;rsquo;m used to them from jquery.&lt;/p&gt;

&lt;p&gt;So there you go, you just programmatically got some information from a webpage. Pretty sweet.
Now, you&amp;rsquo;ll notice that the anchor tag there has a class of report, so what we could instead have done, is return a list of all the report anchors like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;links = driver.find_elements_by_css_selector(&#39;a.report&#39;)
for link in links:
    print link.get_attribute(&#39;href&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;re talking. Notice that was find_element&lt;strong&gt;s&lt;/strong&gt;_by_css_selector, that extra s in there gives us a list of all matches.&lt;/p&gt;

&lt;h2 id=&#34;interacting-with-the-page&#34;&gt;Interacting with the page&lt;/h2&gt;

&lt;p&gt;So sometimes, we&amp;rsquo;re going to have to interact with the page, such as clicking on things, or the bane of all webscrapers, scrolling down. Now a lot of tutorials online make scrolling down a web page sound way more complicated than it ought to be. It should in fact be this easy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def scroll():
   print &#39;Scrolling&#39;
   driver.execute_script(&amp;quot;window.scrollTo(0, document.body.scrollHeight);&amp;quot;)
   time.sleep(5)

for _ in range(12):
    scroll()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That scrolls to the bottom of the page 12 times, waiting for 5 seconds each time to allow items to load. We&amp;rsquo;ve used driver.execute_script() to allow us to use javascript directly on the page. We can use that to click on elements as well. Say there was a tab called &amp;ldquo;stats&amp;rdquo; that didn&amp;rsquo;t have a href and it was the third on a tab bar. We can get the selector from developer tools and click on the tab using the following script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;statsbutton = driver.find_element_by_css_selector(&#39;div.tabs &amp;gt; ul &amp;gt; li:nth-child(3)&#39;)
driver.execute_script(&amp;quot;arguments[0].click();&amp;quot;, statsbutton) 
print &#39;Clicking&#39;
time.sleep(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;again we add a sleep event just to allow any javascript to load. 5 seconds is probably a bit conservative, you can most likely go a bit shorter than that.&lt;/p&gt;

&lt;h2 id=&#34;looping-through-multiple-web-pages&#34;&gt;Looping through multiple web pages&lt;/h2&gt;

&lt;p&gt;So what if you scrape a page to get a whole bunch of urls and then you want to go to each of those pages and get some more information, for example go to each game of the season and collect stats. Well, my recommendation would be to first write your list of urls to file. Because scripting is sometimes a pain in the ass, and you might make a mistake. So you don&amp;rsquo;t want to have to go to the front page every time you make a typo and trawl for links that you&amp;rsquo;ve already collected. So, to write to a file, simply:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file = &#39;gamelinks.txt&#39;
target = open(file, &#39;w&#39;)

for link in links: #links collected earlier in the script.
target.write(&amp;quot;%s\n&amp;quot; % link.get_attribute(&#39;href&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you want to create a new script that goes through your text file and gets the stats. First get the links into a list.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;links = [link.rstrip(&#39;\n&#39;) for link in open(&#39;gamelinks.txt&#39;)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you want to loop through the links. Here is the complete example script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from selenium import webdriver
from selenium.common.exceptions import TimeoutException
import time
import io

driver = webdriver.PhantomJS() # or add to your PATH
driver.set_window_size(1024, 768) # optional

links = [link.rstrip(&#39;\n&#39;) for link in open(&#39;fixtures.txt&#39;)]
linksLength = len(links)

for index, value in enumerate(links):
    print &#39;Starting&#39;
    driver.set_page_load_timeout(60)
    while True:
        try:
            driver.get(value)
        except TimeoutException:
            print &amp;quot;Timeout, retrying...&amp;quot;
            continue
        else:
            break
    print &#39;Sleeping&#39;
    time.sleep(3)
    dataContainer = driver.find_element_by_css_selector(&#39;div.dataContainer&#39;)
    dataJSON = dataContainer.get_attribute(&#39;data-game&#39;)
    file = &#39;data{}.json&#39;.format(index)
    target = io.open(file, &#39;w&#39;, encoding=&amp;quot;utf-8&amp;quot;)
    target.write(dataJSON)
    target.close()
    print &#39;File {} of {} written&#39;.format(index, linksLength - 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So let&amp;rsquo;s go through that. First the usual imports, plus selenium&amp;rsquo;s TimeoutExeption. That&amp;rsquo;s because if a page is too slow, it will crash your script and you&amp;rsquo;ll have to do over, and we don&amp;rsquo;t want that. We&amp;rsquo;ll also import io for writing json, because footballers often have funny names that aren&amp;rsquo;t ascii, so we need utf-8.&lt;/p&gt;

&lt;p&gt;We make an enumerated for loop over the links so that we have access to the index for file naming and printing purposes. You&amp;rsquo;ll notice that there&amp;rsquo;s a lot of printing statements in there. I like to know what&amp;rsquo;s going on while my scripts are running. Web scraping scripts can be excruciatingly slow, so those print statements are a sanity check.&lt;/p&gt;

&lt;p&gt;We do a try except on the driver.get so that we can handle pages that are taking too long.&lt;/p&gt;

&lt;p&gt;So in this example we just happened to stumble upon a website that stores it&amp;rsquo;s data in json format right in a data attribute on the page. Yes this awesomeness does sometimes happen in the real world. In fact, that&amp;rsquo;s how I got the premier league stats from an unidentified website. The rest of the script saves each game&amp;rsquo;s json object to it&amp;rsquo;s own file. Again this is for ease of working with. Also, there are 380 games in a premier league season, if you&amp;rsquo;re script craps out after 250 games or something, you really don&amp;rsquo;t want to start from that start again, as this could take hours.&lt;/p&gt;

&lt;h2 id=&#34;awesome&#34;&gt;Awesome&lt;/h2&gt;

&lt;p&gt;So there you go, that&amp;rsquo;s how to scrape a whole bunch of javascipt rendered webpages that follow a similar template. Easy peasy. It&amp;rsquo;s slow, much slower that pinging the server for the html page, but that&amp;rsquo;s not going to get you much in the days of the single page app.&lt;/p&gt;

&lt;h2 id=&#34;what-now&#34;&gt;What now?&lt;/h2&gt;

&lt;p&gt;So now that we have a whole bunch of JSON files, what are we going to do with them? Well, I suggest storing your data in an SQLite database, and that&amp;rsquo;s what my next post is all about. So join me to see &lt;a href=&#34;https://davejkane.github.io/json-sqlite-csv&#34;&gt;how I made an SQLite file&lt;/a&gt; that contains all of the stats from the &lt;sup&gt;2015&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt; English Premier League season.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://davejkane.github.io/about/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://davejkane.github.io/about/</guid>
      <description>&lt;p&gt;This is my safe space where I can write about things that interest me. Mostly I plan on writing about programming and data, coz I like it. But I might occasionally stray onto other topics. We&amp;rsquo;ll see.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>